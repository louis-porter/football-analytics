{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymc as pm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import requests\n",
    "import io\n",
    "from datetime import datetime, timedelta\n",
    "import multiprocessing\n",
    "import arviz as az\n",
    "import logging\n",
    "import tqdm\n",
    "\n",
    "# get data\n",
    "API_KEY = os.getenv(\"API_KEY\")\n",
    "url = 'https://data-service.beatthebookie.blog/data'\n",
    "headers = {\"x-api-key\": API_KEY}\n",
    "\n",
    "# Function to fetch data for a specific division and season\n",
    "def fetch_data(division, season):\n",
    "    params = {\n",
    "        'division': division,\n",
    "        'season': season\n",
    "    }\n",
    "    response = requests.get(url, headers=headers, params=params)\n",
    "    if response.status_code == 200:\n",
    "        return pd.read_json(io.StringIO(response.content.decode('utf-8')))\n",
    "    else:\n",
    "        print(f\"Error fetching {division} {season}: {response.status_code}\")\n",
    "        print(response.content.decode('utf-8'))\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# Fetch data for all combinations\n",
    "seasons = ['2024_2025', '2023_2024']\n",
    "divisions = ['Premier League', 'Championship']\n",
    "dataframes = []\n",
    "\n",
    "for division in divisions:\n",
    "    for season in seasons:\n",
    "        df = fetch_data(division, season)\n",
    "        if not df.empty:\n",
    "            dataframes.append(df)\n",
    "\n",
    "# Combine all dataframes\n",
    "if dataframes:\n",
    "    df = pd.concat(dataframes, ignore_index=True)\n",
    "    \n",
    "    # Convert match_date to datetime\n",
    "    df['match_date'] = pd.to_datetime(df['match_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build model\n",
    "\n",
    "def build_bayesian_model(home_teams, away_teams, home_goals, away_goals, home_xg, away_xg, dates, leagues):\n",
    "    print(\"Building Bayesian model...\")\n",
    "    print(f\"Dataset size: {len(home_teams)} matches\")\n",
    "    print(f\"Time span: {dates.min()} to {dates.max()}\")\n",
    "    \n",
    "    # get unique teams and leagues\n",
    "    teams = sorted(list(set(home_teams) | set(away_teams))) # alphabetically sorts and de-dupes list of team names\n",
    "    unique_leagues = sorted(list(set(leagues)))\n",
    "\n",
    "    # sets index values for each team/league within a dict\n",
    "    team_indices = {team: idx for idx, team in enumerate(teams)}\n",
    "    league_indices = {league: idx for idx, league in enumerate(unique_leagues)}\n",
    "\n",
    "    # convert date into time differences\n",
    "    max_date = np.max(dates)\n",
    "    time_diffs = (max_date - dates).dt.days\n",
    "\n",
    "    # convert team names to index vals\n",
    "    home_idx = [team_indices[team] for team in home_teams]\n",
    "    away_idx = [team_indices[team] for team in away_teams]\n",
    "\n",
    "    # Get league index for each team directly from the data\n",
    "    home_league_idx = [league_indices[league] for league in leagues]\n",
    "    away_league_idx = [league_indices[league] for league in leagues]\n",
    "    \n",
    "    # Create array of league indices for each team\n",
    "    team_league_idx = np.zeros(len(teams), dtype=int)\n",
    "    for team, idx in team_indices.items():\n",
    "        # Find first occurrence of this team and use its league\n",
    "        if team in home_teams:\n",
    "            first_idx = list(home_teams).index(team)\n",
    "            team_league_idx[idx] = home_league_idx[first_idx]\n",
    "        else:\n",
    "            first_idx = list(away_teams).index(team)\n",
    "            team_league_idx[idx] = away_league_idx[first_idx]\n",
    "\n",
    "    with pm.Model() as model:\n",
    "        # league level parameters for league strengths\n",
    "        league_attack_mu = pm.Normal(\"league_attack_mu\", mu=0, sigma=0.5) # using a normal distribution to infer average league attack value\n",
    "        league_attack_sigma = pm.HalfNormal(\"league_attack_sigma\", sigma=0.5) # using a half normal dist to infer league attack spread, half normal as std must be positive\n",
    "        league_defense_mu = pm.Normal(\"league_defense_mu\", mu=0, sigma=0.5)\n",
    "        league_defense_sigma = pm.HalfNormal(\"league_defense_sigma\", sigma=0.5)\n",
    "\n",
    "        # creating raw league strengths for all leagues EXCEPT Premier League\n",
    "        premier_league_idx = league_indices[\"Premier League\"]\n",
    "        league_strength_raw = pm.Normal(\"league_strength_raw\", mu=-0.5, sigma=0.3, shape=len(unique_leagues)-1) # setting mu to -0.5 as other leagues are expected to be weaker. shape = -1 as Premier league will be 0\n",
    "        league_strength = pm.Deterministic( # deterministic variable as derived from other random variables (league strengths)\n",
    "            \"league_strength\",\n",
    "            pm.math.concatenate([\n",
    "                league_strength_raw[:premier_league_idx],\n",
    "                pm.math.zeros(1), # creating array that will have all league strengths with Premier league in the \"middle\" with 0\n",
    "                league_strength_raw[premier_league_idx:]\n",
    "            ])\n",
    "        )\n",
    "\n",
    "        # team strength initalisation\n",
    "        attack_raw = pm.Normal(\"attack_raw\", mu=0, sigma=1, shape=len(teams)) # initalising normal distribution for relative attacking strength with mean 0 and std of 1\n",
    "        defense_raw = pm.Normal('defense_raw', mu=0, sigma=1, shape=len(teams))\n",
    "\n",
    "        # scale team strengths by league\n",
    "        attack = pm.Deterministic(\n",
    "            \"attack\",\n",
    "            attack_raw * league_attack_sigma + league_attack_mu + league_strength[team_league_idx] # combining raw team strength with league average/std and then penalising by league overall strength\n",
    "        )\n",
    "        defense = pm.Deterministic(\n",
    "            \"defense\",\n",
    "            defense_raw * league_defense_sigma + league_defense_mu + league_strength[team_league_idx]\n",
    "        )\n",
    "\n",
    "        # initalise time decay parameter\n",
    "        decay_rate = pm.HalfNormal(\"decay_rate\", sigma=1.5/365) # balanced prior for decay rate, divided by 365 to account for daily rate\n",
    "\n",
    "        # initalise home advantage\n",
    "        home_advantage = pm.Normal(\"home_advantage\", mu=0.2, sigma=0.1) # initalises home_adv to 0.2 and has std of 0.1 so val can extend or reduce that much\n",
    "\n",
    "        # create time decay factor to apply to expected goals\n",
    "        time_factor = pm.math.exp(-decay_rate * time_diffs)\n",
    "\n",
    "        # expected goals parameter for both xG and goals, applied time decay\n",
    "        home_theta = time_factor * pm.math.exp(attack[home_idx] - defense[away_idx] + home_advantage) # we use exponential so it's always positive and team strengths are multiplicative\n",
    "        away_theta = time_factor * pm.math.exp(attack[away_idx] - defense[home_idx])\n",
    "\n",
    "        # goals likelihood (poisson for actual goals)\n",
    "        home_goals_like = pm.Poisson(\"home_goals\", mu=home_theta, observed=home_goals) \n",
    "        away_goals_like = pm.Poisson(\"away_goals\", mu=away_theta, observed=away_goals)\n",
    "\n",
    "        # xG likelihood (gamma for expected goals)\n",
    "        xg_alpha = pm.HalfNormal(\"xg_alpha\", sigma=1.0) # shape parameter (must be positive hence half normal) - alpha shapes basic form of distribution\n",
    "        home_xg_beta = xg_alpha / home_theta # beta is rate parameter - scales where that form sits on the axis\n",
    "        away_xg_beta = xg_alpha / away_theta # we are setting the mean of the xg distribution to be equal to our team strength rating\n",
    "\n",
    "        # add small constant to not allow 0s which breaks Gamma dist\n",
    "        epsilon = 0.00001\n",
    "        home_xg_adj = home_xg + epsilon\n",
    "        away_xg_adj = away_xg + epsilon\n",
    "\n",
    "        home_xg_like = pm.Gamma(\"home_xg\", alpha=xg_alpha, beta=home_xg_beta, observed=home_xg_adj)\n",
    "        away_xg_like = pm.Gamma(\"away_xg\", alpha=xg_alpha, beta=away_xg_beta, observed=away_xg_adj)\n",
    "\n",
    "        print(\"Model building completed!\")\n",
    "\n",
    "    return model, team_indices, league_indices\n",
    "\n",
    "# Modify the fit_bayesian_model function\n",
    "def fit_bayesian_model(model, draws=1000):\n",
    "    n_cores = min(4, multiprocessing.cpu_count() - 1)\n",
    "    \n",
    "    print(f\"Starting model fitting with {n_cores} cores...\")\n",
    "    print(f\"Planning {draws} draws with 500 tuning steps...\")  # Increased tuning steps\n",
    "    \n",
    "    with model:\n",
    "        # More robust initialization\n",
    "        start = pm.find_MAP(method='powell', progressbar=True)\n",
    "        \n",
    "        # Improved sampling configuration\n",
    "        trace = pm.sample(\n",
    "            draws=draws,\n",
    "            tune=500,  # Increased tuning steps\n",
    "            chains=n_cores,\n",
    "            cores=n_cores,\n",
    "            progressbar=True,\n",
    "            return_inferencedata=True,\n",
    "            init='adapt_diag',\n",
    "            target_accept=0.95,  # Higher target acceptance rate\n",
    "            max_treedepth=12,    # Reduced from 15\n",
    "            step=pm.NUTS(target_accept=0.95),\n",
    "            compute_convergence_checks=True\n",
    "        )\n",
    "        \n",
    "        # Safe handling of diagnostics\n",
    "        try:\n",
    "            divergences = trace.sample_stats.diverging.sum().values\n",
    "            print(f\"\\nDiagnostics:\")\n",
    "            print(f\"Divergences: {divergences}\")\n",
    "            \n",
    "            # Safe R-hat calculation\n",
    "            rhat_vals = az.rhat(trace)\n",
    "            if hasattr(rhat_vals, 'values'):\n",
    "                rhat_min = float(rhat_vals.min().values)\n",
    "                rhat_max = float(rhat_vals.max().values)\n",
    "                print(f\"R-hat range: {rhat_min:.3f} to {rhat_max:.3f}\")\n",
    "            else:\n",
    "                print(\"R-hat statistics not available\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Could not compute some diagnostics: {str(e)}\")\n",
    "        \n",
    "        return trace\n",
    "\n",
    "\n",
    "\n",
    "def get_league_strengths(trace, league_indices):\n",
    "    leagues = list(league_indices.keys())\n",
    "    league_strength_means = trace.posterior['league_strength'].mean(dim=['chain', 'draw']).values\n",
    "    \n",
    "    results = pd.DataFrame({\n",
    "        'league': leagues,\n",
    "        'league_strength': league_strength_means\n",
    "    })\n",
    "    \n",
    "    return results.round(3).sort_values('league_strength', ascending=False)\n",
    "\n",
    "def get_hierarchical_team_strengths(trace, team_indices, league_indices, team_leagues, current_teams):\n",
    "    teams = list(team_indices.keys())\n",
    "    attack_means = trace.posterior['attack'].mean(dim=['chain', 'draw']).values\n",
    "    defense_means = trace.posterior['defense'].mean(dim=['chain', 'draw']).values\n",
    "    home_adv = trace.posterior['home_advantage'].mean(dim=['chain', 'draw']).values\n",
    "    \n",
    "    # Get league strengths for reference\n",
    "    league_strengths = get_league_strengths(trace, league_indices)\n",
    "    \n",
    "    results = pd.DataFrame({\n",
    "        'team': teams,\n",
    "        'league': [team_leagues[team] for team in teams],\n",
    "        'attack_strength': attack_means,\n",
    "        'defense_strength': defense_means,\n",
    "        'overall_strength': (np.exp(attack_means - np.mean(defense_means)) - \n",
    "                           np.exp(np.mean(attack_means) - defense_means)),\n",
    "        'home_advantage': home_adv\n",
    "    })\n",
    "    \n",
    "    # Merge with league strengths\n",
    "    results = results.merge(\n",
    "        league_strengths,\n",
    "        left_on='league',\n",
    "        right_on='league',\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    # Filter current teams and sort\n",
    "    results = (results[results['team'].isin(current_teams)]\n",
    "              .round(3)\n",
    "              .sort_values('overall_strength', ascending=False))\n",
    "    \n",
    "    return results, home_adv\n",
    "\n",
    "def analyze_league_strengths(trace, league_indices, team_indices, team_leagues):\n",
    "    # Get basic league strengths\n",
    "    leagues = list(league_indices.keys())\n",
    "    league_strength_means = trace.posterior['league_strength'].mean(dim=['chain', 'draw']).values\n",
    "    \n",
    "    # Get the posterior distributions for additional analysis\n",
    "    league_attack_mu = trace.posterior['league_attack_mu'].mean(dim=['chain', 'draw']).values\n",
    "    league_attack_sigma = trace.posterior['league_attack_sigma'].mean(dim=['chain', 'draw']).values\n",
    "    league_defense_mu = trace.posterior['league_defense_mu'].mean(dim=['chain', 'draw']).values\n",
    "    league_defense_sigma = trace.posterior['league_defense_sigma'].mean(dim=['chain', 'draw']).values\n",
    "    \n",
    "    # Calculate league-specific metrics\n",
    "    detailed_results = []\n",
    "    \n",
    "    for league in leagues:\n",
    "        league_idx = league_indices[league]\n",
    "        league_teams = [team for team, l in team_leagues.items() if l == league]\n",
    "        \n",
    "        league_data = {\n",
    "            'league': league,\n",
    "            'base_strength': league_strength_means[league_idx],\n",
    "            'attack_variation': league_attack_sigma,  # How much attack strength varies within the league\n",
    "            'defense_variation': league_defense_sigma,  # How much defense strength varies within the league\n",
    "            'num_teams': len(league_teams),\n",
    "            'teams': ', '.join(sorted(league_teams)[:5]) + ('...' if len(league_teams) > 5 else '')\n",
    "        }\n",
    "        \n",
    "        detailed_results.append(league_data)\n",
    "    \n",
    "    results_df = pd.DataFrame(detailed_results)\n",
    "    \n",
    "    # Calculate expected goals adjustment between leagues\n",
    "    for idx, row in results_df.iterrows():\n",
    "        base_league_strength = row['base_strength']\n",
    "        results_df.loc[idx, 'expected_goals_vs_avg'] = np.exp(base_league_strength) - 1\n",
    "    \n",
    "    return results_df.round(3).sort_values('base_strength', ascending=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Bayesian model...\n",
      "Dataset size: 912 matches\n",
      "Time span: 2024-02-10 00:00:00 to 2025-01-26 00:00:00\n",
      "Model building completed!\n",
      "Starting model fitting with 4 cores...\n",
      "Planning 50 draws with 500 tuning steps...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Owner\\dev\\football-analytics\\.venv\\Lib\\site-packages\\pytensor\\tensor\\rewriting\\elemwise.py:1027: UserWarning: Loop fusion failed because the resulting node would exceed the kernel argument limit.\n",
      "  warn(\n",
      "c:\\Users\\Owner\\dev\\football-analytics\\.venv\\Lib\\site-packages\\pytensor\\tensor\\rewriting\\elemwise.py:1027: UserWarning: Loop fusion failed because the resulting node would exceed the kernel argument limit.\n",
      "  warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\Owner\\dev\\football-analytics\\.venv\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \"ipywidgets\" \n",
       "for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\Owner\\dev\\football-analytics\\.venv\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \"ipywidgets\" \n",
       "for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\Owner\\dev\\football-analytics\\.venv\\Lib\\site-packages\\pymc\\tuning\\starting.py:177: RuntimeWarning: Method \n",
       "powell does not use gradient information (jac).\n",
       "  opt_result = minimize(\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\Owner\\dev\\football-analytics\\.venv\\Lib\\site-packages\\pymc\\tuning\\starting.py:177: RuntimeWarning: Method \n",
       "powell does not use gradient information (jac).\n",
       "  opt_result = minimize(\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Owner\\dev\\football-analytics\\.venv\\Lib\\site-packages\\pytensor\\tensor\\rewriting\\elemwise.py:1027: UserWarning: Loop fusion failed because the resulting node would exceed the kernel argument limit.\n",
      "  warn(\n",
      "Only 50 samples per chain. Reliable r-hat and ESS diagnostics require longer chains for accurate estimate.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Invalid keys found in step_kwargs: {'nuts', 'max_treedepth'}. Keys must be step names and values valid kwargs for that stepper. Did you mean {\"nuts\": {\"max_treedepth\": ...}}?",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 25\u001b[0m\n\u001b[0;32m     13\u001b[0m model, team_indices, league_indices \u001b[38;5;241m=\u001b[39m build_bayesian_model(\n\u001b[0;32m     14\u001b[0m         home_teams\u001b[38;5;241m=\u001b[39mdata[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhome_team\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m     15\u001b[0m         away_teams\u001b[38;5;241m=\u001b[39mdata[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maway_team\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     21\u001b[0m         leagues\u001b[38;5;241m=\u001b[39mdata[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdivision\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     22\u001b[0m     )\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Fit model\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m trace \u001b[38;5;241m=\u001b[39m \u001b[43mfit_bayesian_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdraws\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Get results\u001b[39;00m\n\u001b[0;32m     28\u001b[0m team_strengths, home_advantage \u001b[38;5;241m=\u001b[39m get_hierarchical_team_strengths(\n\u001b[0;32m     29\u001b[0m     trace\u001b[38;5;241m=\u001b[39mtrace,\n\u001b[0;32m     30\u001b[0m     team_indices\u001b[38;5;241m=\u001b[39mteam_indices,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     33\u001b[0m     current_teams\u001b[38;5;241m=\u001b[39mcurrent_teams\n\u001b[0;32m     34\u001b[0m )\n",
      "Cell \u001b[1;32mIn[12], line 118\u001b[0m, in \u001b[0;36mfit_bayesian_model\u001b[1;34m(model, draws)\u001b[0m\n\u001b[0;32m    115\u001b[0m start \u001b[38;5;241m=\u001b[39m pm\u001b[38;5;241m.\u001b[39mfind_MAP(method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpowell\u001b[39m\u001b[38;5;124m'\u001b[39m, progressbar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    117\u001b[0m \u001b[38;5;66;03m# Improved sampling configuration\u001b[39;00m\n\u001b[1;32m--> 118\u001b[0m trace \u001b[38;5;241m=\u001b[39m \u001b[43mpm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    119\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdraws\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdraws\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    120\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtune\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Increased tuning steps\u001b[39;49;00m\n\u001b[0;32m    121\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchains\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_cores\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    122\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcores\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_cores\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    123\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprogressbar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    124\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_inferencedata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[43minit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43madapt_diag\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_accept\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.95\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Higher target acceptance rate\u001b[39;49;00m\n\u001b[0;32m    127\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_treedepth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m12\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Reduced from 15\u001b[39;49;00m\n\u001b[0;32m    128\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mNUTS\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget_accept\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.95\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    129\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompute_convergence_checks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[0;32m    130\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;66;03m# Safe handling of diagnostics\u001b[39;00m\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Owner\\dev\\football-analytics\\.venv\\Lib\\site-packages\\pymc\\sampling\\mcmc.py:718\u001b[0m, in \u001b[0;36msample\u001b[1;34m(draws, tune, chains, cores, random_seed, progressbar, progressbar_theme, step, var_names, nuts_sampler, initvals, init, jitter_max_retries, n_init, trace, discard_tuned_samples, compute_convergence_checks, keep_warning_stat, return_inferencedata, idata_kwargs, nuts_sampler_kwargs, callback, mp_ctx, blas_cores, model, **kwargs)\u001b[0m\n\u001b[0;32m    715\u001b[0m         auto_nuts_init \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    717\u001b[0m initial_points \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 718\u001b[0m step \u001b[38;5;241m=\u001b[39m \u001b[43massign_step_methods\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethods\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSTEP_METHODS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    720\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m nuts_sampler \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpymc\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    721\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(step, NUTS):\n",
      "File \u001b[1;32mc:\\Users\\Owner\\dev\\football-analytics\\.venv\\Lib\\site-packages\\pymc\\sampling\\mcmc.py:237\u001b[0m, in \u001b[0;36massign_step_methods\u001b[1;34m(model, step, methods, step_kwargs)\u001b[0m\n\u001b[0;32m    229\u001b[0m         selected \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\n\u001b[0;32m    230\u001b[0m             methods_list,\n\u001b[0;32m    231\u001b[0m             key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m method, var\u001b[38;5;241m=\u001b[39mrv_var, has_gradient\u001b[38;5;241m=\u001b[39mhas_gradient: method\u001b[38;5;241m.\u001b[39m_competence(  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m    232\u001b[0m                 var, has_gradient\n\u001b[0;32m    233\u001b[0m             ),\n\u001b[0;32m    234\u001b[0m         )\n\u001b[0;32m    235\u001b[0m         selected_steps\u001b[38;5;241m.\u001b[39msetdefault(selected, [])\u001b[38;5;241m.\u001b[39mappend(var)\n\u001b[1;32m--> 237\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minstantiate_steppers\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mselected_steps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Owner\\dev\\football-analytics\\.venv\\Lib\\site-packages\\pymc\\sampling\\mcmc.py:147\u001b[0m, in \u001b[0;36minstantiate_steppers\u001b[1;34m(model, steps, selected_steps, step_kwargs)\u001b[0m\n\u001b[0;32m    145\u001b[0m     example_step \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mlist\u001b[39m(selected_steps\u001b[38;5;241m.\u001b[39mkeys()) \u001b[38;5;129;01mor\u001b[39;00m pm\u001b[38;5;241m.\u001b[39mSTEP_METHODS)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    146\u001b[0m     example_step_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(example_step, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 147\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    148\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid key\u001b[39m\u001b[38;5;132;01m{\u001b[39;00ms\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m found in step_kwargs: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00munused_args\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    149\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKeys must be step names and values valid kwargs for that stepper. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    150\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDid you mean \u001b[39m\u001b[38;5;130;01m{{\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexample_step_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;130;01m{{\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexample_arg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m: ...\u001b[39m\u001b[38;5;130;01m}}\u001b[39;00m\u001b[38;5;130;01m}}\u001b[39;00m\u001b[38;5;124m?\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    151\u001b[0m     )\n\u001b[0;32m    153\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(steps) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    154\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m steps[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mValueError\u001b[0m: Invalid keys found in step_kwargs: {'nuts', 'max_treedepth'}. Keys must be step names and values valid kwargs for that stepper. Did you mean {\"nuts\": {\"max_treedepth\": ...}}?"
     ]
    }
   ],
   "source": [
    "data = df[[\"home_team\", \"away_team\", \"home_goals\", \"away_goals\", \"home_xgoals\", \"away_xgoals\", \"match_date\", \"division\"]]\n",
    "\n",
    "# filter to matches only in previous 365 days\n",
    "data = data[data[\"match_date\"] > datetime.now() - timedelta(days=365)]\n",
    "\n",
    "# get list of current teams\n",
    "current_teams = df[df[\"season\"] == 20242025][\"home_team\"].unique()\n",
    "\n",
    "# get list of leagues\n",
    "team_leagues = df[\"division\"].unique()\n",
    "\n",
    "# Build model\n",
    "model, team_indices, league_indices = build_bayesian_model(\n",
    "        home_teams=data['home_team'],\n",
    "        away_teams=data['away_team'],\n",
    "        home_goals=np.array(data['home_goals']),\n",
    "        away_goals=np.array(data['away_goals']),\n",
    "        home_xg=np.array(data[\"home_xgoals\"]),\n",
    "        away_xg=np.array(data[\"away_xgoals\"]),\n",
    "        dates=data[\"match_date\"],\n",
    "        leagues=data[\"division\"]\n",
    "    )\n",
    "    \n",
    "# Fit model\n",
    "trace = fit_bayesian_model(model, draws=50)\n",
    "    \n",
    "# Get results\n",
    "team_strengths, home_advantage = get_hierarchical_team_strengths(\n",
    "    trace=trace,\n",
    "    team_indices=team_indices,\n",
    "    league_indices=league_indices,\n",
    "    team_leagues=team_leagues,\n",
    "    current_teams=current_teams\n",
    ")\n",
    "\n",
    "# Analyze league strengths\n",
    "league_analysis = analyze_league_strengths(\n",
    "    trace=trace,\n",
    "    league_indices=league_indices,\n",
    "    team_indices=team_indices,\n",
    "    team_leagues=team_leagues\n",
    ")\n",
    "\n",
    "# Print results\n",
    "print(\"\\nTeam Strengths:\")\n",
    "print(team_strengths)\n",
    "\n",
    "print(\"\\nLeague Analysis:\")\n",
    "print(league_analysis)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def save_model_results(trace, team_indices, league_indices, team_strengths, league_analysis, filename=None):\n",
    "    \"\"\"Save all model results to a pickle file\"\"\"\n",
    "    if filename is None:\n",
    "        filename = f'model_results_{datetime.now().strftime(\"%Y%m%d\")}.pkl'\n",
    "    \n",
    "    results = {\n",
    "        'trace': trace,\n",
    "        'team_indices': team_indices,\n",
    "        'league_indices': league_indices,\n",
    "        'team_strengths': team_strengths,\n",
    "        'league_analysis': league_analysis\n",
    "    }\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(results, f)\n",
    "    print(f\"Results saved to {filename}\")\n",
    "\n",
    "def load_model_results(filename):\n",
    "    \"\"\"Load model results from pickle file\"\"\"\n",
    "    with open(filename, 'rb') as f:\n",
    "        results = pickle.load(f)\n",
    "    return (results['trace'], results['team_indices'], results['league_indices'], \n",
    "            results['team_strengths'], results['league_analysis'])\n",
    "\n",
    "filename = f'model_results_{datetime.now().strftime(\"%Y%m%d\")}.pkl'\n",
    "save_model_results(trace, team_indices, league_indices, team_strengths, league_analysis, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace, team_indices, league_indices, team_strengths, league_analysis = load_model_results(filename)\n",
    "\n",
    "# Print results\n",
    "print(\"\\nTeam Strengths:\")\n",
    "print(team_strengths)\n",
    "\n",
    "print(\"\\nLeague Analysis:\")\n",
    "print(league_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trace' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 49\u001b[0m\n\u001b[0;32m     44\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDraw Probability: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprediction[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdraw_prob\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     45\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWin Probability: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maway_team\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprediction[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maway_win_prob\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 49\u001b[0m prediction \u001b[38;5;241m=\u001b[39m predict_match(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTottenham\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMan United\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mtrace\u001b[49m, team_indices)   \n\u001b[0;32m     50\u001b[0m print_prediction(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTottenham\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMan United\u001b[39m\u001b[38;5;124m\"\u001b[39m, prediction) \n",
      "\u001b[1;31mNameError\u001b[0m: name 'trace' is not defined"
     ]
    }
   ],
   "source": [
    "def predict_match(home_team, away_team, trace, team_indices):\n",
    "    home_idx = team_indices[home_team]\n",
    "    away_idx = team_indices[away_team]\n",
    "\n",
    "    # returning the range of distributions that teams attack/defense and home_adv could lie between\n",
    "    attack_samples = trace.posterior[\"attack\"].values\n",
    "    defense_samples = trace.posterior[\"defense\"].values\n",
    "    home_advantage = trace.posterior[\"home_advantage\"].values\n",
    "\n",
    "    # use all combinations of strength to make prediction\n",
    "    home_theta = np.exp(attack_samples[..., home_idx] - # ... means use all chains and draws\n",
    "                        defense_samples[..., away_idx] +\n",
    "                        home_advantage)\n",
    "    away_theta = np.exp(attack_samples[...,  away_idx] - \n",
    "                        defense_samples[..., home_idx])\n",
    "    \n",
    "    # calculate mean expected goals from above samples\n",
    "    home_xg = float(home_theta.mean())\n",
    "    away_xg = float(away_theta.mean())\n",
    "\n",
    "    # simulate match many times using Poisson distribution\n",
    "    n_sims = 1000\n",
    "    home_goals = np.random.poisson(home_xg, n_sims)\n",
    "    away_goals = np.random.poisson(away_xg, n_sims)\n",
    "\n",
    "    # Calculate match outcome probabilities\n",
    "    home_wins = np.mean(home_goals > away_goals)\n",
    "    draws = np.mean(home_goals == away_goals)\n",
    "    away_wins = np.mean(home_goals < away_goals)\n",
    "\n",
    "    return {\n",
    "        'home_xg': round(home_xg, 2),\n",
    "        'away_xg': round(away_xg, 2),\n",
    "        'home_win_prob': round(home_wins * 100, 1),\n",
    "        'draw_prob': round(draws * 100, 1),\n",
    "        'away_win_prob': round(away_wins * 100, 1)\n",
    "    }\n",
    "\n",
    "def print_prediction(home_team, away_team, prediction):\n",
    "    \"\"\"Pretty print the match prediction\"\"\"\n",
    "    print(f\"\\nMatch Prediction: {home_team} (H) vs {away_team} (A)\")\n",
    "    print(f\"Expected Goals: {home_team} {prediction['home_xg']} - {prediction['away_xg']} {away_team}\")\n",
    "    print(f\"Win Probability: {home_team}: {prediction['home_win_prob']}%\")\n",
    "    print(f\"Draw Probability: {prediction['draw_prob']}%\")\n",
    "    print(f\"Win Probability: {away_team}: {prediction['away_win_prob']}%\")\n",
    "\n",
    "\n",
    "\n",
    "prediction = predict_match(\"Tottenham\", \"Man United\", trace, team_indices)   \n",
    "print_prediction(\"Tottenham\", \"Man United\", prediction) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
